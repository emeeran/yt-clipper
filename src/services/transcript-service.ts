import { API_ENDPOINTS } from '../ai/api';
import { CacheService } from '../types';

/**
 * YouTube transcript extraction and processing service
 */


export interface TranscriptSegment {
    text: string;
    start: number;
    duration: number;
}

export interface Transcript {
    segments: TranscriptSegment[];
    fullText: string;
    language: string;
    autoGenerated: boolean;
}

export class YouTubeTranscriptService {
    private readonly transcriptTTL = 1000 * 60 * 60; // 1 hour

    constructor(private cache?: CacheService) {}

    /**
     * Extract transcript for a YouTube video
     */
    async getTranscript(videoId: string): Promise<Transcript | null> {
        if (!videoId) {
            throw new Error('Video ID is required');
        }

        const cacheKey = `transcript-${videoId}`;
        const cached = this.cache?.get<Transcript>(cacheKey);
        if (cached) {
            return cached;
        }

        try {
            // Try multiple methods to get transcript
            const transcript = await this.fetchTranscriptWithFallback(videoId);

            if (transcript) {
                this.cache?.set(cacheKey, transcript, this.transcriptTTL);
                return transcript;
            }

            return null;
        } catch (error) {
            
return null;
        }
    }

    /**
     * Fetch transcript using multiple methods with fallback
     */
    private async fetchTranscriptWithFallback(videoId: string): Promise<Transcript | null> {
        // Method 1: Try YouTube API endpoint
        try {
            const transcript = await this.fetchFromYouTubeAPI(videoId);
            if (transcript) return transcript;
        } catch (error) {
            
}

        // Method 2: Try video page scraping
        try {
            const transcript = await this.scrapeTranscriptFromPage(videoId);
            if (transcript) return transcript;
        } catch (error) {
            
}

        // Method 3: Try third-party transcript service
        try {
            const transcript = await this.fetchFromThirdParty(videoId);
            if (transcript) return transcript;
        } catch (error) {
            
}

        return null;
    }

    /**
     * Method 1: Official YouTube transcript API
     */
    private async fetchFromYouTubeAPI(videoId: string): Promise<Transcript | null> {
        const url = `https://video.google.com/timedtext?lang=en&v=${videoId}`;

        const response = await fetch(url);
        if (!response.ok) {
            throw new Error(`Transcript API failed: ${response.status}`);
        }

        const xmlText = await response.text();
        return this.parseXMLTranscript(xmlText, videoId);
    }

    /**
     * Method 2: Scrape transcript from YouTube page
     */
    private async scrapeTranscriptFromPage(videoId: string): Promise<Transcript | null> {
        const videoUrl = `https://www.youtube.com/watch?v=${videoId}`;
        const proxyUrl = `${API_ENDPOINTS.CORS_PROXY}?url=${encodeURIComponent(videoUrl)}`;

        const response = await fetch(proxyUrl);
        if (!response.ok) {
            throw new Error('Failed to fetch video page');
        }

        const html = await response.text();
        const transcriptData = await this.extractTranscriptFromHTML(html);

        if (transcriptData) {
            return this.createTranscript(transcriptData, videoId, true);
        }

        return null;
    }

    /**
     * Method 3: Third-party transcript service (optional)
     */
    private async fetchFromThirdParty(videoId: string): Promise<Transcript | null> {
        // Note: This is a placeholder for third-party services
        // You could integrate with services like:
        // - AssemblyAI
        // - Deepgram
        // - AWS Transcribe
        // - Google Speech-to-Text

        // For now, return null to indicate this method is not implemented
        return null;
    }

    /**
     * Parse XML transcript from YouTube API
     */
    private parseXMLTranscript(xmlText: string, videoId: string): Transcript {
        const parser = new DOMParser();
        const xmlDoc = parser.parseFromString(xmlText, 'text/xml');

        const textElements = xmlDoc.getElementsByTagName('text');
        const segments: TranscriptSegment[] = [];
        let fullText = '';

        for (let i = 0; i < textElements.length; i++) {
            const element = textElements[i];
            if (!element) continue;
            const text = element.textContent || '';
            const start = parseFloat(element.getAttribute('start') || '0');
            const duration = parseFloat(element.getAttribute('dur') || '0');

            if (text.trim()) {
                segments.push({ text: text.trim(), start, duration });
                fullText += text.trim() + ' ';
            }
        }

        return {
            segments,
            fullText: fullText.trim(),
            language: 'en',
            autoGenerated: true
        };
    }

    /**
     * Extract transcript data from YouTube page HTML
     */
    private async extractTranscriptFromHTML(html: string): Promise<TranscriptSegment[] | null> {
        // Look for transcript data in the page JavaScript
        const transcriptRegex = /"captions":\s*{[^}]*"playerCaptionsTracklistRenderer":\s*{[^}]*"captionTracks":\s*\[([^\]]+)\]/;
        const match = html.match(transcriptRegex);

        if (!match || !match[1]) {
            return null;
        }

        try {
            // Extract the JSON part and parse it
            const captionTracksJson = match[1];
            const captionTracks = JSON.parse(`[${captionTracksJson}]`);

            // Find the English caption track
            const englishTrack = captionTracks.find((track: any) =>
                track.languageCode === 'en' || track.languageCode?.startsWith('en')
            );

            if (!englishTrack || !englishTrack.baseUrl) {
                return null;
            }

            // Fetch the transcript content (use promise chain to avoid top-level await
            // parsing issues in some build environments)
            return fetch(englishTrack.baseUrl)
                .then((resp) => {
                    if (!resp.ok) throw new Error('Failed to fetch caption track');
                    return resp.text();
                })
                .then((xmlText) => this.parseXMLTranscript(xmlText, '').segments)
                .catch((err) => {
                    
return null;
                });
        } catch (error) {
            
return null;
        }
    }

    /**
     * Create transcript object from segments
     */
    private createTranscript(
        segments: TranscriptSegment[] | { text: string; start: number; duration?: number }[],
        videoId: string,
        autoGenerated: boolean = false
    ): Transcript {
        if (!Array.isArray(segments)) {
            segments = [segments as any];
        }

        const normalizedSegments = segments.map(seg => ({
            text: seg.text,
            start: seg.start,
            duration: seg.duration || 0
        }));

        const fullText = normalizedSegments
            .map(seg => seg.text)
            .join(' ')
            .trim();

        return {
            segments: normalizedSegments,
            fullText,
            language: 'en',
            autoGenerated
        };
    }

    /**
     * Get transcript summary for quick analysis
     */
    async getTranscriptSummary(
        videoId: string,
        maxLength: number = 2000
    ): Promise<string | null> {
        const transcript = await this.getTranscript(videoId);
        if (!transcript) {
            return null;
        }

        // If transcript is short enough, return full text
        if (transcript.fullText.length <= maxLength) {
            return transcript.fullText;
        }

        // For longer transcripts, return key segments
        const keySegments = transcript.segments
            .filter(seg => seg.text.length > 20) // Filter out very short segments
            .slice(0, 10) // Take first 10 meaningful segments
            .map(seg => seg.text)
            .join(' ');

        return keySegments.length > maxLength
            ? keySegments.substring(0, maxLength) + '...'
            : keySegments;
    }

    /**
     * Extract key time-stamped moments from transcript
     */
    async extractKeyMoments(videoId: string, count: number = 5): Promise<Array<{time: number, text: string}> | null> {
        const transcript = await this.getTranscript(videoId);
        if (!transcript || transcript.segments.length === 0) {
            return null;
        }

        // Filter segments by length (ignore very short ones)
        const meaningfulSegments = transcript.segments.filter(seg => seg.text.length > 30);

        if (meaningfulSegments.length === 0) {
            return null;
        }

        // Distribute segments evenly throughout the video
        const totalSegments = meaningfulSegments.length;
        const step = Math.max(1, Math.floor(totalSegments / count));

        const keyMoments: Array<{time: number, text: string}> = [];
        for (let i = 0; i < totalSegments && keyMoments.length < count; i += step) {
            const segment = meaningfulSegments[i];
            if (!segment) continue;
            keyMoments.push({
                time: segment.start,
                text: segment.text
            });
        }

        return keyMoments;
    }

    /**
     * Check if transcript is available for a video
     */
    async isTranscriptAvailable(videoId: string): Promise<boolean> {
        const transcript = await this.getTranscript(videoId);
        return transcript !== null && transcript.segments.length > 0;
    }
}